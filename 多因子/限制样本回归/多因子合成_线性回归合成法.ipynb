{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多因子研究的需求\n",
    "2. 核心需求：需要有长期稳定又表现优异的因子\n",
    "3. 时间长度： 2010至今（数据需要重新下）\n",
    "4. 样本内：2010.1-2016.12\n",
    "5. 样本外：2017.1-2018.4\n",
    "6. 市值板块： ZZ800\n",
    "7. 持有时间： 20天\n",
    "8. 因子处理要求：先去极值，再进行行业中性化，最后标准化\n",
    "9. IC值：负需要调整为正，且大于0.05，IC_IR越大越好\n",
    "\n",
    "如何满足需求？参考多因子课件，复现与设计因子都可选用\n",
    "多因子组合（更稳，更准，更有效）\n",
    "\n",
    "1.  交集并集\n",
    "2.  等权合成\n",
    "3.  动态加权\n",
    "\n",
    "最后需要输出的文件：\n",
    "\n",
    "1.  ipynb\n",
    "2.  .py\n",
    "3.  Excel表格\n",
    "4.  Pdf图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from jaqs_fxdayu.util import dp\n",
    "from jaqs.data.dataapi import DataApi\n",
    "import jaqs_fxdayu\n",
    "jaqs_fxdayu.patch_all()\n",
    "from jaqs.data import DataView\n",
    "from jaqs.data import RemoteDataService\n",
    "from jaqs_fxdayu.data.dataservice import LocalDataService\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "api = DataApi(addr='tcp://data.tushare.org:8910')\n",
    "api.login(\"18523827661\", \n",
    "          'eyJhbGciOiJIUzI1NiJ9.eyJjcmVhdGVfdGltZSI6IjE1MjIxMTc0NDY1MzAiLCJpc3MiOiJhdXRoMCIsImlkIjoiMTg1MjM4Mjc2NjEifQ.AO9Rp8jG_IWc6crPrBOC-ujMP0-g1S1c5kUlTs5qwrk'\n",
    ")\n",
    "start = 20100101\n",
    "end = 20180401\n",
    "\n",
    "SH_id = dp.index_cons(api, \"000300.SH\", start, end)\n",
    "SZ_id = dp.index_cons(api, \"000905.SH\", start, end)\n",
    "\n",
    "stock_symbol = list(set(SH_id.symbol)|set(SZ_id.symbol))\n",
    "factor_list = ['volume','float_mv','pb','pe','ps','end_bal_cash']\n",
    "check_factor = ','.join(factor_list)\n",
    "dataview_folder = '/Users/adam/Desktop/intern/test5/fxdayu_adam/data'\n",
    "dataview_folder2 = 'muti_factor/'\n",
    "dv = DataView()\n",
    "#ds = LocalDataService(fp=dataview_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Begin: DataApi login 18523827661@tcp://data.tushare.org:8910\n",
      "    login success \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0,'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_config = {\n",
    "    \"remote.data.address\": \"tcp://data.tushare.org:8910\",\n",
    "    \"remote.data.username\": \"18523827661\",\n",
    "    \"remote.data.password\": \"eyJhbGciOiJIUzI1NiJ9.eyJjcmVhdGVfdGltZSI6IjE1MjIxMTc0NDY1MzAiLCJpc3MiOiJhdXRoMCIsImlkIjoiMTg1MjM4Mjc2NjEifQ.AO9Rp8jG_IWc6crPrBOC-ujMP0-g1S1c5kUlTs5qwrk\"\n",
    "}\n",
    "ds = RemoteDataService()\n",
    "ds.init_from_config(data_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataview loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "#dv.save_dataview(dataview_folder2)\n",
    "dv.load_dataview(dataview_folder2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "factor_lis = ['alpha32_','alpha42_','alpha62_','alpha64_','alpha194','alpha195','alpha197','Beta3','alpha211','pe','ps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "id_zz500 = dp.daily_index_cons(api, \"000300.SH\", start, end)\n",
    "id_hs300 = dp.daily_index_cons(api, \"000905.SH\", start, end)\n",
    "\n",
    "columns_500 = list(set(id_zz500.columns)-set(id_hs300.columns))\n",
    "def limit_up_down():\n",
    "    trade_status = dv.get_ts('trade_status').fillna(0)\n",
    "    mask_sus = trade_status == 0\n",
    "    # 涨停\n",
    "    up_limit = dv.add_formula('up_limit', '(close - Delay(close, 1)) / Delay(close, 1) > 0.095', is_quarterly=False)\n",
    "    # 跌停\n",
    "    down_limit = dv.add_formula('down_limit', '(close - Delay(close, 1)) / Delay(close, 1) < -0.095', is_quarterly=False)\n",
    "    can_enter = np.logical_and(up_limit < 1, ~mask_sus) # 未涨停未停牌\n",
    "    can_exit = np.logical_and(down_limit < 1, ~mask_sus) # 未跌停未停牌\n",
    "    return can_enter,can_exit\n",
    "\n",
    "id_member = pd.concat([id_zz500[columns_500],id_hs300],axis=1)\n",
    "mask = ~id_member\n",
    "can_enter,can_exit = limit_up_down()\n",
    "\n",
    "alpha_signal = factor_lis\n",
    "price = dv.get_ts('close_adj')\n",
    "sw1 = dv.get_ts('sw1')\n",
    "dict_classify = {'480000': '银行', '430000': '房地产', '460000': '休闲服务', '640000': '机械设备', '240000': '有色金属', '510000': '综合', '410000': '公用事业', '450000': '商业贸易', '730000': '通信', '330000': '家用电器', '720000': '传媒', '630000': '电气设备', '270000': '电子', '490000': '非银金融', '370000': '医药生物', '710000': '计算机', '280000': '汽车', '340000': '食品饮料', '220000': '化工', '210000': '采掘', '230000': '钢铁', '650000': '国防军工', '110000': '农林牧渔', '420000': '交通运输', '620000': '建筑装饰', '350000': '纺织服装', '610000': '建筑材料', '360000': '轻工制造'}\n",
    "sw1_name = sw1.replace(dict_classify)\n",
    "sw1 = sw1_name\n",
    "can_enter = can_enter.reindex(columns=price.columns,index=price.index)\n",
    "can_exit = can_exit.reindex(columns=price.columns,index=price.index)\n",
    "mask = mask.reindex(columns=price.columns,index=price.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from jaqs_fxdayu.research import SignalDigger\n",
    "from jaqs_fxdayu.research.signaldigger import analysis\n",
    "\n",
    "def cal_obj(signal, name, period, quantile):\n",
    "    price_bench = dv.data_benchmark\n",
    "    obj = SignalDigger(output_folder=\"hs300/%s\" % name,\n",
    "                       output_format='pdf')\n",
    "    obj.process_signal_before_analysis(signal,\n",
    "                                   price=price,\n",
    "                                   n_quantiles=quantile, \n",
    "                                   period=period,\n",
    "                                   mask=mask,\n",
    "                                   group=sw1,\n",
    "                                   can_enter = can_enter,\n",
    "                                   can_exit = can_exit,\n",
    "                                   commission = 0.0003\n",
    "                                   )\n",
    "    obj.create_full_report()\n",
    "    return obj\n",
    "\n",
    "def plot_pfm(signal, name, period=5, quantile=5):\n",
    "    obj = cal_obj(signal, name, period, quantile)\n",
    "def signal_data(signal, name, period=5, quantile=5):\n",
    "    print(name)\n",
    "    obj = cal_obj(signal, name, period, quantile)\n",
    "    return obj.signal_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "with open(\"neutral_pos.pkl\",'rb') as f2:\n",
    "    factor_dict = pickle.load(f2)\n",
    "factor_dict2 = dict()\n",
    "for each in factor_lis:\n",
    "    factor_dict2[each] = factor_dict[each]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "signals_name = ['alpha32_','alpha42_','alpha62_','alpha64_','alpha194','alpha195','alpha197','Beta3','alpha211','pe','ps']\n",
    "signals_name.append('ret20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#当期数据\n",
    "period = 20\n",
    "factor_dict['ret20'] = jutil.to_quantile(dv.get_ts('close_adj').pct_change(period),n_quantiles=5)\n",
    "X1 = pd.DataFrame(columns = signals_name)\n",
    "for signal_name in signals_name:\n",
    "    X1[signal_name] = factor_dict[signal_name].stack()\n",
    "    \n",
    "'''\n",
    "#滞后一期数据\n",
    "\n",
    "X2 = pd.DataFrame(columns = signals_name)\n",
    "for signal_name in signals_name:\n",
    "    X2[signal_name] = factor_dict[signal_name].shift(1).stack()\n",
    "\n",
    "#之后两期数据\n",
    "X3 = pd.DataFrame(columns = signals_name)\n",
    "for signal_name in signals_name:\n",
    "    X3[signal_name] = factor_dict[signal_name].shift(2).stack()\n",
    "X1_ = X1_.join(X3,rsuffix='_3') \n",
    "\n",
    "X1_ = X1.join(X2,rsuffix='_2')\n",
    "'''\n",
    "X1_ = X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#这一步选择样本使用，在看效果的时候为了省时间，只用了2016以后的样本\n",
    "train_indexer = dv.get_ts('close_adj').loc[:20160101].stack().index.values\n",
    "test_indexer = dv.get_ts('close_adj').loc[20160101:].stack().index.values\n",
    "#X = X1_.loc[test_indexer]\n",
    "X = X1_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = dv.get_ts('close_adj').pct_change(period).shift(-period).stack().reindex(index = X.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import jaqs.util as jutil\n",
    "Y_q = jutil.to_quantile(dv.get_ts('close_adj').pct_change(period).shift(-period),n_quantiles=5)\n",
    "Y_q_clip = Y_q.stack().reindex(index = X.index)\n",
    "Y_q_clip = Y_q_clip[np.logical_or(Y_q_clip == 1.0,Y_q_clip == 5.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_clip = Y.reindex(index = Y_q_clip.index)\n",
    "Y_clip_class = pd.Series(np.where(Y_q_clip == 5.0,1,0),index = Y_q_clip.index)\n",
    "X_clip = X.reindex(index = Y_q_clip.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split(X,max_train_size=5,period = 1):\n",
    "    n = len(X)\n",
    "    lis = []\n",
    "    for i in range(1,n):\n",
    "        pred_index = [n-i]\n",
    "        if (n-i-max_train_size-period)>=0:\n",
    "            train_index = [j for j in range(n-i-max_train_size-period,n-i-period)]\n",
    "            lis.append((train_index,pred_index))\n",
    "    lis.reverse()\n",
    "    return lis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n"
     ]
    }
   ],
   "source": [
    "stock_num = dv.get_ts('close_adj').shape[1]\n",
    "time_index = X.unstack().index.values\n",
    "tscv = TimeSeriesSplit(max_train_size=5,n_splits=300)\n",
    "pred = []\n",
    "i = 0\n",
    "#预处理\n",
    "for train_index, pred_index in split(X.unstack().index.values,max_train_size=120,period=period):\n",
    "    i+=1\n",
    "    indexer = [slice(None)] * 2\n",
    "    indexer[X.index.names.index('trade_date')] = time_index[train_index]\n",
    "    indexer2 = [slice(None)] * 2\n",
    "    indexer2[X.index.names.index('trade_date')] = time_index[pred_index]\n",
    "    #clf = RFR(max_depth=3,min_samples_leaf=9,max_leaf_nodes=4)\n",
    "    #clf = SVR(C = 1)\n",
    "    #clf = LinearRegression()\n",
    "    #clf = Ridge()\n",
    "    clf = LogisticRegression()\n",
    "    X_ = X_clip.loc[tuple(indexer),:]\n",
    "    X_train = X_.dropna(how = 'any', axis = 0)\n",
    "    X__ = X.loc[tuple(indexer2),:]\n",
    "    X_pred = X__.dropna(how = 'any', axis = 0)\n",
    "    if len(X_train) == 0 or len(X_pred) == 0:\n",
    "        print(\"%d为空\"%i)\n",
    "        continue\n",
    "    #Y_train = Y_clip.reindex(index = X_train.index).dropna()\n",
    "    Y_train = Y_clip_class.reindex(index = X_train.index).dropna()\n",
    "    X_train = X_train.reindex(index = Y_train.index)\n",
    "    clf.fit(X_train,Y_train)\n",
    "    #prediction = clf.predict(X_pred)\n",
    "    prediction = clf.predict_proba(X_pred)[:,1]\n",
    "    pred_ser = pd.Series(prediction,index = X_pred.index)\n",
    "    pred.append(pred_ser)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adamzzz\n",
      "Nan Data Count (should be zero) : 0;  Percentage of effective data: 41%\n",
      "\n",
      "\n",
      "Value of signals of Different Quantiles Statistics\n",
      "               min       max      mean       std  count    count %\n",
      "quantile                                                          \n",
      "1         0.101118  0.476849  0.385485  0.060945  34459  20.066035\n",
      "2         0.425503  0.532540  0.485755  0.018605  34352  20.003727\n",
      "3         0.499143  0.587922  0.536778  0.015537  34354  20.004891\n",
      "4         0.538642  0.661303  0.581735  0.018599  34352  20.003727\n",
      "5         0.575713  0.860721  0.644739  0.037150  34211  19.921620\n",
      "Figure saved: /Users/adam/Desktop/intern/test5/fxdayu_adam/hs300/Adamzzz/returns_report.pdf\n",
      "Information Analysis\n",
      "                 ic\n",
      "IC Mean       0.085\n",
      "IC Std.       0.104\n",
      "t-stat(IC)   13.617\n",
      "p-value(IC)   0.000\n",
      "IC Skew      -0.033\n",
      "IC Kurtosis  -0.294\n",
      "Ann. IR       0.811\n",
      "Figure saved: /Users/adam/Desktop/intern/test5/fxdayu_adam/hs300/Adamzzz/information_report.pdf\n"
     ]
    }
   ],
   "source": [
    "pred_factor = pred[0].append(pred[1:])\n",
    "signal_data_ = signal_data(pred_factor.unstack().loc[20170101:],'Adamzzz',period=20,quantile=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "factor_dict['pred_factor'] = pred_factor.reindex(index = X.index).unstack()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
